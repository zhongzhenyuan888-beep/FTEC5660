{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFaf7VErZ1Bf"
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3g3k3W-qfAv"
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vsESFZylO6O"
   },
   "source": [
    "## Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 28985,
     "status": "ok",
     "timestamp": 1770953029174,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "Hrdfpmv9nMpw",
    "outputId": "53774ca2-0aca-4537-9e31-8e3f44611cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Collecting markitdown[pdf]\n",
      "  Downloading markitdown-0.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
      "Collecting magika~=0.6.1 (from markitdown[pdf])\n",
      "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting markdownify (from markitdown[pdf])\n",
      "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
      "Collecting pdfminer-six (from markitdown[pdf])\n",
      "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
      "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown[pdf])\n",
      "  Downloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
      "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
      "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six->markitdown[pdf]) (43.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six->markitdown[pdf]) (2.0.0)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six->markitdown[pdf]) (3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
      "Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
      "Downloading markitdown-0.1.4-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pdfminer_six-20260107-py3-none-any.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.24.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime, markdownify, pdfminer-six, magika, markitdown\n",
      "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.4 onnxruntime-1.24.1 pdfminer-six-20260107\n",
      "Collecting langchain_mcp_adapters\n",
      "  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.9-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.9)\n",
      "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.62.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain_mcp_adapters)\n",
      "  Downloading langchain_core-1.2.12-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.17.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.6.9)\n",
      "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.50.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.40.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.13.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n",
      "Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl (22 kB)\n",
      "Downloading langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-1.1.9-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.8/85.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading langchain_core-1.2.12-py3-none-any.whl (500 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m500.1/500.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: filetype, langchain-core, langchain-openai, langchain_mcp_adapters, langchain_google_genai\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.9\n",
      "    Uninstalling langchain-core-1.2.9:\n",
      "      Successfully uninstalled langchain-core-1.2.9\n",
      "Successfully installed filetype-1.2.0 langchain-core-1.2.12 langchain-openai-1.1.9 langchain_google_genai-4.2.0 langchain_mcp_adapters-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests PyPDF2 gdown\n",
    "!pip install 'markitdown[pdf]'\n",
    "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUav-7KdaY_W"
   },
   "source": [
    "## Setup your API key\n",
    "\n",
    "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
    "\n",
    "\n",
    "1.   Look for the key icon on the left panel of your colab.\n",
    "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
    "3. Copy your key to `Value`.\n",
    "\n",
    "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5384,
     "status": "ok",
     "timestamp": 1770953138635,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "ueILmCPHci9v"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
    "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRbStil_qkQc"
   },
   "source": [
    "# Download sample CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCENjOq6owDd"
   },
   "source": [
    "## Downloading sample_cv.pdf\n",
    "The codes below download the sample CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 12777,
     "status": "ok",
     "timestamp": 1770953630237,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "1kCCp8DwPF4L",
    "outputId": "65255950-8bc4-47b2-cee4-3f4e82ac46a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
      "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
      "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
      "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
      "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
      "To: /content/downloaded_cvs/CV_1.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 45.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
      "To: /content/downloaded_cvs/CV_2.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 32.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
      "To: /content/downloaded_cvs/CV_3.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 39.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
      "To: /content/downloaded_cvs/CV_4.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 40.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
      "To: /content/downloaded_cvs/CV_5.pdf\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 52.6MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['downloaded_cvs/CV_1.pdf',\n",
       " 'downloaded_cvs/CV_2.pdf',\n",
       " 'downloaded_cvs/CV_3.pdf',\n",
       " 'downloaded_cvs/CV_4.pdf',\n",
       " 'downloaded_cvs/CV_5.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gdown\n",
    "\n",
    "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
    "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
    "\n",
    "output_dir = \"downloaded_cvs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "gdown.download_folder(\n",
    "    url=folder_url,\n",
    "    output=output_dir,\n",
    "    quiet=False,\n",
    "    use_cookies=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1576,
     "status": "ok",
     "timestamp": 1770953635327,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "2akmVn9LODIu",
    "outputId": "9a1a43bd-3797-4af3-c084-56ac617a1ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“„ CV_1.pdf\n",
      "================================================================================\n",
      "John Smith\n",
      "\n",
      "Marketing Professional\n",
      "\n",
      "+ Singapore, Singapore (cid:209) Kowloon\n",
      "\n",
      "Experience\n",
      "\n",
      "Engineer, ByteDance\n",
      "\n",
      "2020 â€“ Present\n",
      "\n",
      "â€¢ Worked in a fast-paced, global technology environment.\n",
      "\n",
      "â€¢ Collaborated across teams to support large-scale platforms.\n",
      "\n",
      "â€¢ Applied analytical and problem-solving skills in production systems.\n",
      "\n",
      "Education\n",
      "\n",
      "McGill University\n",
      "\n",
      "Bachelor of Science (BSc) in Marketing\n",
      "\n",
      "Skills\n",
      "\n",
      "Content Creation\n",
      "\n",
      "SEO\n",
      "\n",
      "Social Media\n",
      "\n",
      "Graduated 2009\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“„ CV_2.pdf\n",
      "================================================================================\n",
      "Minh Pham\n",
      "Design Professional\n",
      "\n",
      "Beijing, China | Hong Kong\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "Manager, BCG\n",
      "\n",
      "2022 â€“ Present\n",
      "\n",
      "â€¢ Led cross-functional teams on client-facing design initiatives.\n",
      "\n",
      "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
      "\n",
      "â€¢ Applied design thinking to business and strategy problems.\n",
      "\n",
      "Analyst, Tencent\n",
      "\n",
      "2013 â€“ 2017\n",
      "\n",
      "â€¢ Conducted market and product analysis to support decision-making.\n",
      "\n",
      "â€¢ Collaborated with design and engineering teams.\n",
      "\n",
      "â€¢ Produced reports and insights for senior leadership.\n",
      "\n",
      "Education\n",
      "\n",
      "BSc in Design\n",
      "The University of Hong Kong\n",
      "\n",
      "Skills\n",
      "\n",
      "â€¢ UI/UX Design\n",
      "\n",
      "â€¢ Prototyping\n",
      "\n",
      "â€¢ Graphic Design\n",
      "\n",
      "2011\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“„ CV_3.pdf\n",
      "================================================================================\n",
      "Wei Zhang\n",
      "Consulting Professional\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "2013 â€“ Present\n",
      "\n",
      "Engineer, PwC\n",
      "\n",
      "Munich, Germany\n",
      "Sydney (Hometown)\n",
      "\n",
      "â€¢ Supported consulting engagements across multiple client\n",
      "\n",
      "projects.\n",
      "\n",
      "â€¢ Performed data analysis to inform strategic recommen-\n",
      "\n",
      "dations.\n",
      "\n",
      "â€¢ Collaborated with cross-functional teams in a profes-\n",
      "\n",
      "sional services environment.\n",
      "\n",
      "Education\n",
      "\n",
      "2015\n",
      "\n",
      "Skills\n",
      "\n",
      "BSc in Consulting\n",
      "University of Tokyo\n",
      "\n",
      "Analytical\n",
      "Business\n",
      "\n",
      "Data Analysis, Problem Solving\n",
      "Strategy, PowerPoint\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“„ CV_4.pdf\n",
      "================================================================================\n",
      "Rahul Sharma\n",
      "Legal Professional\n",
      "Singapore (Hometown) | Singapore / Philippines\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "2021 â€“ 2027\n",
      "\n",
      "Senior Engineer, Microsoft\n",
      "\n",
      "â€¢ Led compliance-focused initiatives within large-scale techni-\n",
      "\n",
      "cal teams.\n",
      "\n",
      "â€¢ Advised on regulatory, legal, and risk considerations for com-\n",
      "\n",
      "plex systems.\n",
      "\n",
      "â€¢ Worked at the intersection of law, technology, and gover-\n",
      "\n",
      "nance.\n",
      "\n",
      "2020 â€“ 2023\n",
      "\n",
      "Consultant, StartupXYZ\n",
      "\n",
      "â€¢ Provided legal and strategic consulting for early-stage com-\n",
      "\n",
      "panies.\n",
      "\n",
      "â€¢ Supported contract review, compliance, and operational risk\n",
      "\n",
      "management.\n",
      "\n",
      "â€¢ Engaged with cross-functional and international stakehold-\n",
      "\n",
      "ers.\n",
      "\n",
      "Education\n",
      "\n",
      "2021\n",
      "\n",
      "Skills\n",
      "\n",
      "PhD in Legal Studies\n",
      "Tsinghua University\n",
      "\n",
      "Compliance, Litigation, Contract Review\n",
      "Web3, Machine Learning, Quantum Computing\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ“„ CV_5.pdf\n",
      "================================================================================\n",
      "Rahul Sharma\n",
      "AI Professional\n",
      "London | Hong Kong | Singapore (Hometown)\n",
      "\n",
      "Core Skills\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "Machine Learning & AI\n",
      "\n",
      "â€¢ Advanced AI Systems\n",
      "\n",
      "â€¢ Machine Learning (ML)\n",
      "\n",
      "Senior Engineer\n",
      "EY\n",
      "\n",
      "Current\n",
      "\n",
      "â€¢ Designed and evaluated AI-driven solutions for\n",
      "\n",
      "enterprise clients.\n",
      "\n",
      "â€¢ Applied ML techniques to large-scale business\n",
      "\n",
      "â€¢ Natural Language Processing (NLP)\n",
      "\n",
      "Frameworks & Tools\n",
      "\n",
      "problems.\n",
      "\n",
      "Consultant\n",
      "StartupXYZ\n",
      "\n",
      "2019 â€“ 2021\n",
      "\n",
      "â€¢ TensorFlow\n",
      "\n",
      "â€¢ PyTorch\n",
      "\n",
      "â€¢ Python\n",
      "\n",
      "Education\n",
      "\n",
      "â€¢ Provided AI and data strategy advisory to\n",
      "\n",
      "early-stage companies.\n",
      "\n",
      "Senior Analyst\n",
      "DataForge\n",
      "\n",
      "2016 â€“ Present\n",
      "\n",
      "â€¢ Conducted advanced data analysis and model\n",
      "\n",
      "evaluation.\n",
      "\n",
      "Lead Scientist\n",
      "UrbanFlow\n",
      "\n",
      "2010 â€“ 2017\n",
      "\n",
      "PhD in Artificial Intelligence\n",
      "University of Tokyo\n",
      "2012\n",
      "\n",
      "â€¢ Led research initiatives in applied AI systems.\n",
      "\n",
      "â€¢ Mentored junior researchers and engineers.\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "#  Load and display all CV PDFs in order\n",
    "# =====================================================\n",
    "import os\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "cv_dir = \"downloaded_cvs\"\n",
    "\n",
    "# Initialize MarkItDown\n",
    "md = MarkItDown(enable_plugins=False)\n",
    "\n",
    "# Collect and sort PDFs numerically\n",
    "pdf_files = sorted(\n",
    "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
    "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
    ")\n",
    "\n",
    "all_cvs = []\n",
    "\n",
    "for pdf_name in pdf_files:\n",
    "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
    "    result = md.convert(pdf_path)\n",
    "\n",
    "    all_cvs.append({\n",
    "        \"file\": pdf_name,\n",
    "        \"text\": result.text_content\n",
    "    })\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸ“„ {pdf_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result.text_content)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA2GvPWTQFt9"
   },
   "source": [
    "# Connect to our MCP server\n",
    "\n",
    "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
    "\n",
    "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mbkH9xHXfmK"
   },
   "source": [
    "## Check which tools that the MCP server provide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6888,
     "status": "ok",
     "timestamp": 1770953149854,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "6h0311KbN9A3",
    "outputId": "e45ade01-7669-4b18-b0a4-56659d8412c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_facebook_users\n",
      "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
      "\n",
      "Args:\n",
      "    q: Search query string (case-insensitive, matches any part of display name)\n",
      "       Examples: \"John\", \"john smith\", \"Smith\"\n",
      "    limit: Maximum number of results to return (default: 20, max: 20)\n",
      "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
      "\n",
      "Returns:\n",
      "    List of user dictionaries, each containing:\n",
      "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
      "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
      "    - city (str): Current city of residence\n",
      "    - country (str): Country of residence\n",
      "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
      "    \n",
      "    Returns empty list [] if no matches found.\n",
      "\n",
      "Example:\n",
      "    search_facebook_users(\"Alex Chan\", limit=5)\n",
      "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
      "    \n",
      "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
      "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
      "\n",
      "Use case:\n",
      "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
      "    personal information, location, and social connections. Handles typos and variations.\n",
      "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_facebook_profile\n",
      "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
      "\n",
      "Args:\n",
      "    user_id: Facebook user ID obtained from search_facebook_users()\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - id (int): Facebook user ID\n",
      "    - display_name (str): Public display name (may be nickname)\n",
      "    - original_name (str): Original/legal name from LinkedIn\n",
      "    - city (str): Current city\n",
      "    - country (str): Current country\n",
      "    - hometown (str|None): City/region where user grew up\n",
      "    - bio (str): Personal biography/interests\n",
      "    - status (str|None): Relationship status (Single, Married, etc.)\n",
      "    - education (str|None): Highest education level\n",
      "    - current_job (str|None): Current job title\n",
      "    - current_company (str|None): Current employer\n",
      "    - interests (str): Comma-separated hobbies/interests\n",
      "    - friends (List[int]): List of friend user IDs\n",
      "    - posts (List[dict]): Recent posts with id and content\n",
      "    \n",
      "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
      "\n",
      "Example:\n",
      "    get_facebook_profile(123)\n",
      "    â†’ {\n",
      "        \"id\": 123,\n",
      "        \"display_name\": \"Sam Chan\",\n",
      "        \"original_name\": \"Alex Chan\",\n",
      "        \"city\": \"Hong Kong\",\n",
      "        \"hometown\": \"Kowloon\",\n",
      "        \"bio\": \"Software professional | Photography enthusiast\",\n",
      "        \"status\": \"Married\",\n",
      "        \"current_job\": \"Senior Engineer\",\n",
      "        \"current_company\": \"Google\",\n",
      "        \"friends\": [124, 125, 126],\n",
      "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Verify candidate's personal details, check for name discrepancies,\n",
      "    validate current employment, and assess social connections.\n",
      "{'user_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_facebook_mutual_friends\n",
      "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
      "\n",
      "Args:\n",
      "    user_id_1: First Facebook user ID\n",
      "    user_id_2: Second Facebook user ID\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - user_1_id (int): First user's ID\n",
      "    - user_2_id (int): Second user's ID\n",
      "    - mutual_friends (List[int]): List of shared friend IDs\n",
      "    - mutual_count (int): Number of mutual friends\n",
      "    \n",
      "    Returns {\"error\": \"...\"} if either user not found.\n",
      "\n",
      "Example:\n",
      "    get_facebook_mutual_friends(123, 456)\n",
      "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
      "\n",
      "Use case:\n",
      "    Verify professional or personal relationships claimed in CV/references.\n",
      "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "search_linkedin_people\n",
      "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
      "\n",
      "Args:\n",
      "    q: Search query (matches name, headline, summary, or skill names)\n",
      "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
      "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
      "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
      "    industry: Filter by industry (optional, case-insensitive)\n",
      "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
      "    limit: Maximum results to return (default: 20, max: 20)\n",
      "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
      "\n",
      "Returns:\n",
      "    List of profile dictionaries, each containing:\n",
      "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
      "    - name (str): Full name\n",
      "    - headline (str): Professional headline/title\n",
      "    - industry (str): Industry sector\n",
      "    - location (str): \"City, Country\" format\n",
      "    - years_experience (int): Total years of work experience\n",
      "    - match_type (str): \"exact\" or \"fuzzy\"\n",
      "    \n",
      "    Returns empty list [] if no matches found.\n",
      "\n",
      "Example:\n",
      "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
      "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
      "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
      "    \n",
      "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
      "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
      "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
      "\n",
      "Use case:\n",
      "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
      "    Use location filter to narrow down results when common names exist. Handles typos.\n",
      "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_linkedin_profile\n",
      "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
      "\n",
      "Args:\n",
      "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - id (int): LinkedIn profile ID\n",
      "    - name (str): Full name\n",
      "    - headline (str): Professional headline\n",
      "    - city (str): Current city\n",
      "    - country (str): Current country\n",
      "    - industry (str): Primary industry\n",
      "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
      "    - years_experience (int): Total years of professional experience\n",
      "    - summary (str): Professional summary/bio\n",
      "    \n",
      "    - skills (List[dict]): Each containing:\n",
      "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
      "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
      "    \n",
      "    - experience (List[dict]): Work history, each containing:\n",
      "        * company (str): Employer name\n",
      "        * title (str): Job title\n",
      "        * seniority (str): Level (junior, mid, senior)\n",
      "        * start_year (int): Employment start year\n",
      "        * end_year (int|None): Employment end year (None if current)\n",
      "        * is_current (bool): Whether currently employed here\n",
      "    \n",
      "    - education (List[dict]): Academic history, each containing:\n",
      "        * school (str): Institution name\n",
      "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
      "        * field (str): Field of study\n",
      "        * start_year (int): Start year\n",
      "        * end_year (int): Graduation year\n",
      "    \n",
      "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
      "\n",
      "Example:\n",
      "    get_linkedin_profile(456)\n",
      "    â†’ {\n",
      "        \"id\": 456,\n",
      "        \"name\": \"Alex Chan\",\n",
      "        \"headline\": \"Senior Software Engineer\",\n",
      "        \"years_experience\": 8,\n",
      "        \"skills\": [\n",
      "            {\"name\": \"Python\", \"proficiency\": 5},\n",
      "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
      "        ],\n",
      "        \"experience\": [\n",
      "            {\n",
      "                \"company\": \"Google\",\n",
      "                \"title\": \"Senior Engineer\",\n",
      "                \"seniority\": \"senior\",\n",
      "                \"start_year\": 2020,\n",
      "                \"end_year\": None,\n",
      "                \"is_current\": True\n",
      "            }\n",
      "        ],\n",
      "        \"education\": [\n",
      "            {\n",
      "                \"school\": \"HKUST\",\n",
      "                \"degree\": \"BSc\",\n",
      "                \"field\": \"Computer Science\",\n",
      "                \"start_year\": 2010,\n",
      "                \"end_year\": 2014\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Primary tool for CV verification - compare claimed experience, education,\n",
      "    skills, and employment dates against LinkedIn ground truth.\n",
      "{'person_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n",
      "get_linkedin_interactions\n",
      "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
      "\n",
      "Args:\n",
      "    person_id: LinkedIn profile ID\n",
      "\n",
      "Returns:\n",
      "    Dictionary containing:\n",
      "    - profile_id (int): The person's LinkedIn ID\n",
      "    - post_count (int): Number of posts made\n",
      "    - total_likes (int): Total likes received across all posts\n",
      "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
      "    - engagement_score (float): Likes per post ratio\n",
      "    \n",
      "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
      "\n",
      "Example:\n",
      "    get_linkedin_interactions(456)\n",
      "    â†’ {\n",
      "        \"profile_id\": 456,\n",
      "        \"post_count\": 10,\n",
      "        \"total_likes\": 150,\n",
      "        \"liked_by\": [123, 124, 125],\n",
      "        \"engagement_score\": 15.0\n",
      "    }\n",
      "\n",
      "Use case:\n",
      "    Assess professional network strength and content engagement.\n",
      "    Verify connections to claimed colleagues or industry peers.\n",
      "{'person_id': {'type': 'integer'}}\n",
      "\n",
      "\n",
      "------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient({\n",
    "    \"social_graph\": {\n",
    "        \"transport\": \"http\",\n",
    "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
    "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
    "    }\n",
    "})\n",
    "\n",
    "mcp_tools = await client.get_tools()\n",
    "for tool in mcp_tools:\n",
    "    print(tool.name)\n",
    "    print(tool.description)\n",
    "    print(tool.args)\n",
    "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABoe2-qfXl7r"
   },
   "source": [
    "## A simple agent using tools from the MCP server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5787,
     "status": "ok",
     "timestamp": 1770953746702,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "VUagst_XEVmy",
    "outputId": "b7913da7-da25-468c-9c67-8493feea594a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools loaded successfully: ['search_facebook_users', 'get_facebook_profile', 'get_facebook_mutual_friends', 'search_linkedin_people', 'get_linkedin_profile', 'get_linkedin_interactions']\n",
      "LLM initialized and tools bound.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import asyncio\n",
    "from google.colab import userdata # \n",
    "from langchain_openai import ChatOpenAI  # \n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# ==========================================\n",
    "# 1. Connect to MCP Server ()\n",
    "# ==========================================\n",
    "client = MultiServerMCPClient({\n",
    "    \"social_graph\": {\n",
    "        \"transport\": \"http\",\n",
    "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
    "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
    "    }\n",
    "})\n",
    "\n",
    "# Fetch tools )\n",
    "# We use 'await' here because fetching tools is an asynchronous network request.\n",
    "#  awaitï¼Œã€‚\n",
    "mcp_tools = await client.get_tools()\n",
    "tools = mcp_tools\n",
    "tool_map = {tool.name: tool for tool in tools}\n",
    "\n",
    "print(f\"Tools loaded successfully: {[t.name for t in tools]}\")\n",
    "\n",
    "# ==========================================\n",
    "#\n",
    "# ==========================================\n",
    "# Using ChatOpenAI client which is compatible with AIHubMix\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    api_key=userdata.get('AIHUBMIX_API_KEY'),\n",
    "    base_url=\"https://aihubmix.com/v1\", # \n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "print(\"LLM initialized and tools bound.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10031,
     "status": "ok",
     "timestamp": 1770953798630,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "1C7yaf6yEgfG",
    "outputId": "bc924504-6a4f-48b4-c25c-36db3fd40466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Starting manual tool tests...\n",
      "\n",
      "--- Test 1: Search Facebook (Alex Chan) ---\n",
      "Result: [{'type': 'text', 'text': '[{\"id\":3,\"display_name\":\"Alex Chan\",\"city\":\"Hyderabad\",\"country\":\"India\",\"match_type\":\"exact\"},{\"id\":41,\"display_name\":\"Alex Chan\",\"city\":\"Shanghai\",\"country\":\"China\",\"match_type\":\"exact\"}]', 'id': 'lc_967eb888-53be-4433-ad89-65b115b2429c'}]\n",
      "\n",
      "--- Test 2: Search Facebook Fuzzy (Alx Chn) ---\n",
      "Result: [{'type': 'text', 'text': '[{\"id\":3,\"display_name\":\"Alex Chan\",\"city\":\"Hyderabad\",\"country\":\"India\",\"match_type\":\"fuzzy\"},{\"id\":41,\"display_name\":\"Alex Chan\",\"city\":\"Shanghai\",\"country\":\"China\",\"match_type\":\"fuzzy\"}]', 'id': 'lc_ec711c4d-2397-4b90-903d-8e6c026bb830'}]\n",
      "\n",
      "--- Test 3: Get LinkedIn Profile (ID=1) ---\n",
      "Result: [{'type': 'text', 'text': '{\"id\":1,\"name\":\"An Tran\",\"headline\":\"Consulting Professional\",\"city\":\"Manila\",\"country\":\"Philippines\",\"industry\":\"Consulting\",\"status\":\"employed\",\"years_experience\":4,\"summa...\n",
      "\n",
      "âœ… Manual tests completed. Tools are responsive.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Step 2: Test Tools Manually (\n",
    "# =====================================================\n",
    "print(\"ğŸ” Starting manual tool tests...\\n\")\n",
    "\n",
    "# 1. Test Search Facebook (Exact Match)\n",
    "# Check what data implies for \"Alex Chan\"\n",
    "\n",
    "print(\"--- Test 1: Search Facebook (Alex Chan) ---\")\n",
    "res1 = await tool_map['search_facebook_users'].ainvoke({'q': \"Alex Chan\", 'limit': 2})\n",
    "print(f\"Result: {res1}\")\n",
    "\n",
    "# 2. Test Search Facebook (Fuzzy Match)\n",
    "# Check if typo \"Alx Chn\" can be resolved\n",
    "\n",
    "print(\"\\n--- Test 2: Search Facebook Fuzzy (Alx Chn) ---\")\n",
    "res2 = await tool_map['search_facebook_users'].ainvoke({'q': \"Alx Chn\", 'limit': 2, 'fuzzy': True})\n",
    "print(f\"Result: {res2}\")\n",
    "\n",
    "# 3. Test Get LinkedIn Profile\n",
    "# Try to fetch profile for ID 1 (Assuming ID 1 exists in DB)\n",
    "\n",
    "print(\"\\n--- Test 3: Get LinkedIn Profile (ID=1) ---\")\n",
    "try:\n",
    "    res3 = await tool_map['get_linkedin_profile'].ainvoke({'person_id': 1})\n",
    "    print(f\"Result: {str(res3)[:200]}...\") # Print first 200 chars only\n",
    "except Exception as e:\n",
    "    print(f\"Test 3 failed: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Manual tests completed. Tools are responsive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1770957485781,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "nHGeiTBbNfp0"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Step 3: Define Agent Logic & Prompt (Fixed & Optimized)\n",
    "# =====================================================\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are a highly analytical CV Verification Agent designed for recruitment compliance and KYC (Know Your Customer). Your goal is to cross-verify CV claims against the SocialGraph MCP database (LinkedIn/Facebook).\n",
    "\n",
    "### I. MANDATORY GUIDING PRINCIPLES (TA QA COMPLIANT):\n",
    "1. **The \"Nearest Profile\" Rule**: Every CV is derived from a real profile in the database. You MUST find the profile that shares the most core attributes (Education/Company) even if other details (like location or job title) have been tampered with or contain \"injected noise\"[cite: 120, 123, 124].\n",
    "2. **Prioritize Hard Facts**:\n",
    "    - High Weight: University names, Degree levels (BSc/PhD), and Employer/Company names[cite: 153].\n",
    "    - Low Weight (Noise-Prone): Specific city locations, exact Job Titles, and Skill names[cite: 118, 119].\n",
    "3. **No Pre-Verification Rejection**: Do NOT reject a CV based on internal inconsistencies (e.g., impossible locations or overlapping dates) before using tools. Use these flaws only as data points for the final score[cite: 112, 121].\n",
    "\n",
    "### II. VERIFICATION WORKFLOW:\n",
    "1. **Broad Identity Search**:\n",
    "    - Start by searching the candidate's name using `search_linkedin_people` without location or industry filters to avoid missing profiles due to \"noise\"[cite: 235].\n",
    "    - Use `fuzzy=True` if an exact name search returns no results[cite: 259].\n",
    "2. **Detailed Profile Analysis**:\n",
    "    - Iterate through the top 3-5 profile IDs using `get_linkedin_profile`[cite: 271].\n",
    "    - Match profiles based on the **School Name** and **Major Employers** listed on the CV.\n",
    "3. **Social Presence & Network Strength**:\n",
    "    - Use `search_facebook_users` to cross-verify personal details such as `hometown` or `original_name`[cite: 161, 191].\n",
    "    - Optionally use `get_linkedin_interactions` to assess if the candidate has a realistic professional network[cite: 317].\n",
    "4. **Discrepancy Detection**:\n",
    "    - Compare degrees (e.g., CV claims PhD, but MCP shows BSc)[cite: 154].\n",
    "    - Check timelines for logical impossibilities (e.g., two full-time \"Senior\" roles in different countries simultaneously).\n",
    "\n",
    "### III. SCORING & REPORTING LOGIC:\n",
    "- **RELIABILITY_SCORE > 0.5 (PASS)**: The candidate exists. Discrepancies are minor (typos in cities, varied job titles, or unconventional degree naming)[cite: 121, 123].\n",
    "- **RELIABILITY_SCORE <= 0.5 (FAIL)**: Clear evidence of fabrication, such as claiming non-existent high-level degrees, false employers, or complete timeline overlaps that indicate the CV is not a truthful representation of the MCP profile[cite: 157].\n",
    "\n",
    "### IV. OUTPUT FORMAT:\n",
    "1. **Verification Summary**: List what matched and what didn't.\n",
    "2. **Flagged Issues**: Highlight major red flags (e.g., Degree mismatch).\n",
    "3. **Final Conclusion**: You MUST end with exactly this format:\n",
    "RELIABILITY_SCORE: [float between 0.0 and 1.0]\n",
    "\"\"\"\n",
    "# 2. \n",
    "def clean_tool_result(result):\n",
    "    \"\"\"\n",
    "    Ref: Peer's code.\n",
    "    Extracts only the 'text' content from tool result to save tokens.\n",
    "    Prevents the LLM context from overflowing and cutting off the report.\n",
    "    \"\"\"\n",
    "    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict):\n",
    "        return result[0].get(\"text\", str(result))\n",
    "    return str(result)\n",
    "\n",
    "# 3. Agent \n",
    "async def run_agent(messages, llm_with_tools, tool_map, max_iterations=15):\n",
    "    print(\"ğŸ¤– Agent is thinking...\")\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        \n",
    "        response = await llm_with_tools.ainvoke(messages)\n",
    "        messages.append(response)\n",
    "\n",
    "        \n",
    "        if not response.tool_calls:\n",
    "            return response.content, messages\n",
    "\n",
    "        \n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "            tool_id = tool_call[\"id\"]\n",
    "\n",
    "            print(f\"  ğŸ”§ Calling: {tool_name} | Args: {tool_args}\")\n",
    "\n",
    "            if tool_name in tool_map:\n",
    "                try:\n",
    "                    # \n",
    "                    raw_result = await tool_map[tool_name].ainvoke(tool_args)\n",
    "\n",
    "                    # --- \n",
    "                    result_text = clean_tool_result(raw_result)\n",
    "\n",
    "                    # \n",
    "                    if result_text == \"[]\" or result_text == \"\":\n",
    "                        result_text = \"[] (No results. Try fuzzy search or remove industry filter)\"\n",
    "                    # ---------------------------------------------\n",
    "\n",
    "                except Exception as e:\n",
    "                    result_text = f\"Error: {str(e)}\"\n",
    "            else:\n",
    "                result_text = f\"Error: Tool {tool_name} not found.\"\n",
    "\n",
    "            # \n",
    "            print(f\"    -> Result: {result_text[:100]}...\")\n",
    "\n",
    "            messages.append(ToolMessage(\n",
    "                content=result_text,\n",
    "                tool_call_id=tool_id\n",
    "            ))\n",
    "\n",
    "    return \"Max iterations reached.\", messages\n",
    "\n",
    "def extract_score(text):\n",
    "    match = re.search(r\"RELIABILITY_SCORE\\s*:\\s*([0-9]*\\.?[0-9]+)\", text)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231244,
     "status": "ok",
     "timestamp": 1770957724397,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "9H2mVK-FFGJT",
    "outputId": "5fa8b7b9-1273-4be3-bfbd-afcf4e047214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸ“„ Processing: CV_1.pdf\n",
      "============================================================\n",
      "ğŸ¤– Agent is thinking...\n",
      "  ğŸ”§ Calling: search_linkedin_people | Args: {'q': 'John Smith'}\n",
      "    -> Result: [{\"id\":8,\"name\":\"John Smith\",\"headline\":\"Finance Professional\",\"industry\":\"Finance\",\"location\":\"Kowl...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 9}\n",
      "    -> Result: {\"id\":9,\"name\":\"John Smith\",\"headline\":\"Marketing Professional\",\"city\":\"Singapore\",\"country\":\"Singap...\n",
      "\n",
      "âœ… Finished CV_1.pdf\n",
      "ğŸ“Š Score: 0.7\n",
      "ğŸ“ Report Snippet: **Verification Summary:**\n",
      "\n",
      "*   **Name:** John Smith - Matches LinkedIn profile (ID 9).\n",
      "*   **Headline:** Marketing Professional - Matches LinkedIn pro...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“„ Processing: CV_2.pdf\n",
      "============================================================\n",
      "ğŸ¤– Agent is thinking...\n",
      "  ğŸ”§ Calling: search_linkedin_people | Args: {'q': 'Minh Pham'}\n",
      "    -> Result: [{\"id\":47,\"name\":\"Minh Pham\",\"headline\":\"Design Professional\",\"industry\":\"Design\",\"location\":\"Beijin...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 47}\n",
      "    -> Result: {\"id\":47,\"name\":\"Minh Pham\",\"headline\":\"Design Professional\",\"city\":\"Beijing\",\"country\":\"China\",\"ind...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 180}\n",
      "    -> Result: {\"id\":180,\"name\":\"Minh Pham\",\"headline\":\"Consulting Professional\",\"city\":\"Central\",\"country\":\"Hong K...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 415}\n",
      "    -> Result: {\"id\":415,\"name\":\"Minh Pham\",\"headline\":\"Design Professional\",\"city\":\"Ho Chi Minh City\",\"country\":\"V...\n",
      "  ğŸ”§ Calling: search_facebook_users | Args: {'q': 'Minh Pham'}\n",
      "    -> Result: [{\"id\":62,\"display_name\":\"Minh Pham\",\"city\":\"Austin\",\"country\":\"USA\",\"match_type\":\"exact\"},{\"id\":70,...\n",
      "  ğŸ”§ Calling: get_facebook_profile | Args: {'user_id': 70}\n",
      "    -> Result: {\"id\":70,\"display_name\":\"Minh Pham\",\"original_name\":\"Minh Pham\",\"city\":\"Beijing\",\"country\":\"China\",\"...\n",
      "\n",
      "âœ… Finished CV_2.pdf\n",
      "ğŸ“Š Score: 0.9\n",
      "ğŸ“ Report Snippet: **Verification Summary**:\n",
      "\n",
      "*   **Matched**:\n",
      "    *   The candidate's name, \"Minh Pham\", was found on both LinkedIn and Facebook.\n",
      "    *   LinkedIn Profi...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“„ Processing: CV_3.pdf\n",
      "============================================================\n",
      "ğŸ¤– Agent is thinking...\n",
      "  ğŸ”§ Calling: search_linkedin_people | Args: {'q': 'Wei Zhang'}\n",
      "    -> Result: [{\"id\":24,\"name\":\"Wei Zhang\",\"headline\":\"Legal Professional\",\"industry\":\"Legal\",\"location\":\"Sydney, ...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 97}\n",
      "    -> Result: {\"id\":97,\"name\":\"Wei Zhang\",\"headline\":\"Consulting Professional\",\"city\":\"Munich\",\"country\":\"Germany\"...\n",
      "\n",
      "âœ… Finished CV_3.pdf\n",
      "ğŸ“Š Score: 1.0\n",
      "ğŸ“ Report Snippet: Verification Summary:\n",
      "The LinkedIn profile for Wei Zhang (ID: 97) matches the CV's core information.\n",
      "- Name: Matches \"Wei Zhang\".\n",
      "- Professional Exper...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“„ Processing: CV_4.pdf\n",
      "============================================================\n",
      "ğŸ¤– Agent is thinking...\n",
      "  ğŸ”§ Calling: search_linkedin_people | Args: {'q': 'Rahul Sharma'}\n",
      "    -> Result: [{\"id\":4,\"name\":\"Rahul Sharma\",\"headline\":\"Education Professional\",\"industry\":\"Education\",\"location\"...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 7}\n",
      "    -> Result: {\"id\":7,\"name\":\"Rahul Sharma\",\"headline\":\"Legal Professional\",\"city\":\"Sha Tin\",\"country\":\"Hong Kong\"...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 91}\n",
      "    -> Result: {\"id\":91,\"name\":\"Rahul Sharma\",\"headline\":\"Legal Professional\",\"city\":\"Cebu\",\"country\":\"Philippines\"...\n",
      "\n",
      "âœ… Finished CV_4.pdf\n",
      "ğŸ“Š Score: 0.4\n",
      "ğŸ“ Report Snippet: Verification Summary:\n",
      "*   **Name:** Rahul Sharma - Matched on LinkedIn (Profile ID 91) and Facebook (Profile ID 100).\n",
      "*   **Education:**\n",
      "    *   CV: P...\n",
      "\n",
      "\n",
      "============================================================\n",
      "ğŸ“„ Processing: CV_5.pdf\n",
      "============================================================\n",
      "ğŸ¤– Agent is thinking...\n",
      "  ğŸ”§ Calling: search_linkedin_people | Args: {'q': 'Rahul Sharma'}\n",
      "    -> Result: [{\"id\":4,\"name\":\"Rahul Sharma\",\"headline\":\"Education Professional\",\"industry\":\"Education\",\"location\"...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 95}\n",
      "    -> Result: {\"id\":95,\"name\":\"Rahul Sharma\",\"headline\":\"AI Professional\",\"city\":\"Kowloon\",\"country\":\"Hong Kong\",\"...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 552}\n",
      "    -> Result: {\"id\":552,\"name\":\"Rahul Sharma\",\"headline\":\"AI Professional\",\"city\":\"Seattle\",\"country\":\"USA\",\"indus...\n",
      "  ğŸ”§ Calling: get_linkedin_profile | Args: {'person_id': 12}\n",
      "    -> Result: {\"id\":12,\"name\":\"Rahul Sharma\",\"headline\":\"Logistics Professional\",\"city\":\"London\",\"country\":\"UK\",\"i...\n",
      "  ğŸ”§ Calling: search_facebook_users | Args: {'q': 'Rahul Sharma'}\n",
      "    -> Result: [{\"id\":4,\"display_name\":\"Rahul Sharma\",\"city\":\"Berlin\",\"country\":\"Germany\",\"match_type\":\"exact\"},{\"i...\n",
      "\n",
      "âœ… Finished CV_5.pdf\n",
      "ğŸ“Š Score: 0.3\n",
      "ğŸ“ Report Snippet: Verification Summary:\n",
      "The candidate's CV for Rahul Sharma was compared against LinkedIn profile ID 95, which was identified as the nearest profile due...\n",
      "\n",
      "\n",
      "============================================================\n",
      "All CVs processed.\n",
      "Final Scores: [0.7, 0.9, 1.0, 0.4, 0.3]\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Main Execution Loop \n",
    "# =====================================================\n",
    "\n",
    "final_scores = []\n",
    "verification_reports = []\n",
    "\n",
    "# Iterate through all loaded CVs\n",
    "# éå† all_cvs \n",
    "for cv_data in all_cvs:\n",
    "    file_name = cv_data['file']\n",
    "    cv_text = cv_data['text']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“„ Processing: {file_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Construct the user task\n",
    "    \n",
    "    user_task = f\"\"\"\n",
    "    Here is the candidate's CV content:\n",
    "\n",
    "    === CV START ===\n",
    "    {cv_text}\n",
    "    === CV END ===\n",
    "\n",
    "    Please verify this candidate using the tools. Find any discrepancies and output the RELIABILITY_SCORE.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize conversation history\n",
    "    # \n",
    "    messages = [\n",
    "        SystemMessage(content=SYSTEM_PROMPT),\n",
    "        HumanMessage(content=user_task)\n",
    "    ]\n",
    "\n",
    "    # Run the agent\n",
    "    # \n",
    "    try:\n",
    "        response_text, _ = await run_agent(messages, llm_with_tools, tool_map)\n",
    "\n",
    "        # Extract score\n",
    "        # \n",
    "        score = extract_score(response_text)\n",
    "        final_scores.append(score)\n",
    "        verification_reports.append(response_text)\n",
    "\n",
    "        print(f\"\\nâœ… Finished {file_name}\")\n",
    "        print(f\"ğŸ“Š Score: {score}\")\n",
    "        # Print a snippet of the report for debugging\n",
    "        print(f\"ğŸ“ Report Snippet: {response_text[:150]}...\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Critical Error processing {file_name}: {e}\")\n",
    "        final_scores.append(0.0) # Fail safe score\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All CVs processed.\")\n",
    "print(f\"Final Scores: {final_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqO99iOlq6mc"
   },
   "source": [
    "# Evaluation code\n",
    "\n",
    "In the test phase, you will be given 5 CV files with fixed names:\n",
    "\n",
    "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
    "\n",
    "Your system must process these CVs and output a list of 5 scores,\n",
    "one score per CV, in the same order:\n",
    "\n",
    "    scores = [s1, s2, s3, s4, s5]\n",
    "\n",
    "Each score must be a float in the range [0, 1], representing the\n",
    "reliability or confidence that the CV is valid (or meets the task criteria).\n",
    "\n",
    "The ground-truth labels are binary:\n",
    "\n",
    "    groundtruth = [0 or 1, ..., 0 or 1]\n",
    "\n",
    "Each CV is evaluated independently using a threshold of 0.5:\n",
    "\n",
    "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
    "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
    "- Otherwise â†’ No credit\n",
    "\n",
    "In other words, 0.5 is the decision threshold.\n",
    "\n",
    "- Each CV contributes equally.\n",
    "- Final score = (number of correct decisions) / 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1770954420810,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "0TtL07airIqz"
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "#  Evaluation code\n",
    "# =====================================================\n",
    "\n",
    "def evaluate(scores, groundtruth, threshold=0.5):\n",
    "    \"\"\"\n",
    "    scores: list of floats in [0, 1], length = 5\n",
    "    groundtruth: list of ints (0 or 1), length = 5\n",
    "    \"\"\"\n",
    "    assert len(scores) == 5\n",
    "    assert len(groundtruth) == 5\n",
    "\n",
    "    correct = 0\n",
    "    decisions = []\n",
    "\n",
    "    for s, gt in zip(scores, groundtruth):\n",
    "        pred = 1 if s > threshold else 0\n",
    "        decisions.append(pred)\n",
    "        if pred == gt:\n",
    "            correct += 1\n",
    "\n",
    "    final_score = correct / len(scores)\n",
    "\n",
    "    return {\n",
    "        \"decisions\": decisions,\n",
    "        \"correct\": correct,\n",
    "        \"total\": len(scores),\n",
    "        \"final_score\": final_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1770957733823,
     "user": {
      "displayName": "zhong zhenyuan",
      "userId": "06069495220249980496"
     },
     "user_tz": -480
    },
    "id": "okxGqPC7HDjs",
    "outputId": "62e1294a-b42e-4616-dad6-09b52996e80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Result ===\n",
      "{'decisions': [1, 1, 1, 0, 0], 'correct': 5, 'total': 5, 'final_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Evaluation ()\n",
    "# =====================================================\n",
    "\n",
    "# Pass the calculated scores to the evaluation function\n",
    "#\n",
    "scores = final_scores\n",
    "\n",
    "# Ground truth provided by the TA (Do not modify)\n",
    "# \n",
    "groundtruth = [1, 1, 1, 0, 0]\n",
    "\n",
    "# Calculate accuracy\n",
    "# \n",
    "result = evaluate(scores, groundtruth)\n",
    "print(\"\\n=== Evaluation Result ===\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1pEQ7KaHTRVsmDvoHg8NMRuXJO3Jr5avD",
     "timestamp": 1770952603309
    },
    {
     "file_id": "1EMg1-uQwEi8Slnyc3XHz-2UvH7m_KUAo",
     "timestamp": 1769596740969
    },
    {
     "file_id": "1ujms2dBdN5Ht2GYQ2NSng02kTvckh6zy",
     "timestamp": 1768495751866
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
